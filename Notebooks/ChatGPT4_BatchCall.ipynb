{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20223,
     "status": "ok",
     "timestamp": 1726844340442,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "KXaE3if10N4_",
    "outputId": "8c13c71c-5fde-4896-fc70-88b82b07121c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#upload drive to batch process\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7574,
     "status": "ok",
     "timestamp": 1726844349323,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "87jFA4x-99tv",
    "outputId": "5c275840-91d1-458a-eb88-2d16d12e75d2"
   },
   "outputs": [],
   "source": [
    "pip install openai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1726844352911,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "Vq0_NF5i-JXt"
   },
   "outputs": [],
   "source": [
    "#API Key\n",
    "api_key = \"YOUR-API-KEY-HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1726844353802,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "QjkWc-iw-ZjF"
   },
   "outputs": [],
   "source": [
    "batch_directory = '/folder/of/images/to/process'\n",
    "test_image_path = '/optional/test/img/path'\n",
    "is_interior = True #if you are processing interior images, set this to True, else set it to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1726844355447,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "AEHHfrYV-3Li"
   },
   "outputs": [],
   "source": [
    "category_options = \"[wall, floor, ceiling, column, beam, window, door, countertop, shelf, equipment, furniture, other]\" #there is a balancing-act with the level of detail with these categories. Sometimes fewer options is better for GPT.\n",
    "material_options = \"[concrete, metal, wood, brick, glass, quartz, granite, stone, gypsum, plastic, tile, carpet, other]\"\n",
    "\n",
    "ext_category_options = \"[building, other]\"\n",
    "ext_material_options = \"[concrete, metal, wood, brick, glass, stone, plastic, other]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3993,
     "status": "ok",
     "timestamp": 1726844360966,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "rn1bjyro-PMG"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1726844365213,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "AUa-kob0-TBY"
   },
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1726844370476,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "PLpesLPE_EZw"
   },
   "outputs": [],
   "source": [
    "def build_prompt(is_interior:bool, additional_context:str):\n",
    "  return (\n",
    "    \"You are an architect and possess deep knowledge of the built world. You understand how buildings go together and the materials that constitute them.\"\n",
    "    \"Your job is to help your client identify the parts of their building and what they are made of.\"\n",
    "    f\"Attached is an image of {'an interior room' if is_interior else 'a building exterior'}. \"\n",
    "    f\"{additional_context}\"\n",
    "    \"There is a single red outline around a segmented region of the image. \"\n",
    "    \"Your response to me will be in the form of a plus-separated (PSV) line of text with the following format: {description}+{family}+{category}+{material} \"\n",
    "    \"First, write a text description, of what the region is enclosing.\"\n",
    "    \"Make this as detailed as possible, including the types of things inside the boundary and what materials they are made of. Pay attention to textures as these may provide clues.\"\n",
    "    \"Remember that your description should only describe what is inside the outline, not things that are nearby it.\"\n",
    "    \"Record this in the {description} field of the PSV. \"\n",
    "    \"Next, based on your text description, determine if this is attached to the building or not. Examples of things that are not attached are furniture and plants.\"\n",
    "    \"Record your answer to this as either 'attached' or 'loose' in the {family} field of the PSV.\"\n",
    "    \"Next, based on your text description, determine which one of the following categories the text description fits in, \"\n",
    "    f\"only choose one: {category_options if is_interior else ext_category_options}. Do not choose anything that is not on this list.\"\n",
    "    \"Record this in the {category} field of the PSV. \"\n",
    "    \"Next, based on your original text description, determine which of the following materials the text description fits in, \"\n",
    "    f\"only choose one: {material_options if is_interior else ext_material_options}. Do not choose anything that is not on this list.\"\n",
    "    \"Record this in the {material} field of the PSV. \"\n",
    "    \"Remember, do not include any other words/characters in your response except those that fill in the plus-separate line as described above\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1726844383376,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "x5uYVtFWJE0R"
   },
   "outputs": [],
   "source": [
    "# Encode image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "  \n",
    "def classify_image(image_path, is_interior, additional_context=\"\"):\n",
    "\n",
    "  headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = build_payload(image_path, is_interior, additional_context)\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  response_data = response.json()\n",
    "  # Response printed as  a list here\n",
    "  #response_list = json.dumps(response_data, indent=4)\n",
    "  #print(response_list)\n",
    "  return response_data\n",
    "\n",
    "def build_batch_call_line(custom_id, image_path, is_interior, additional_context=\"\"):\n",
    "  line = {\n",
    "      \"custom_id\": f\"{custom_id}\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": build_payload(image_path, is_interior, additional_context)\n",
    "  }\n",
    "  return line\n",
    "\n",
    "def build_payload(image_path, is_interior, additional_context=\"\"):\n",
    "  # base64 string\n",
    "  base64_image = encode_image(image_path)\n",
    "  text_prompt = build_prompt(is_interior, additional_context)\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": text_prompt,\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpg;base64,{base64_image}\",\n",
    "            }\n",
    "          },\n",
    "          # {\n",
    "          #   \"type\": \"image_url\",\n",
    "          #   \"image_url\": {\n",
    "          #     \"url\": f\"data:image/png;base64,{base64_image_02}\",\n",
    "          #   }\n",
    "          # },\n",
    "        ],\n",
    "      },\n",
    "    ],\n",
    "    \"max_tokens\": 500\n",
    "  }\n",
    "\n",
    "  return payload\n",
    "\n",
    "def extract_response_content(complete_response):\n",
    "  return complete_response['choices'][0]['message']['content']\n",
    "\n",
    "def batch_process(dir, is_interior, additional_context=\"\"):\n",
    "  files = get_ordered_files(dir)\n",
    "\n",
    "  responses = {}\n",
    "  i = 1\n",
    "  c = len(files)\n",
    "  for file in files:\n",
    "    r = classify_image(file, is_interior, additional_context)\n",
    "    responses[file] = r \n",
    "    print(f\"Completed image {i} of {c}\")\n",
    "    i+=1\n",
    "\n",
    "  return responses\n",
    "\n",
    "def get_ordered_files(dir):\n",
    "  files = []\n",
    "  for file in os.listdir(dir):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        files.append(os.path.join(dir, file))\n",
    "  files.sort(key=sorting_name)\n",
    "  return files\n",
    "\n",
    "def sorting_name(image_path:str):\n",
    "  parts = image_path.split('.')\n",
    "  if (len(parts) < 2):\n",
    "    return image_path\n",
    "  wo_ext = parts[len(parts) - 2]\n",
    "  parts = wo_ext.split('/')\n",
    "  length = len(parts)\n",
    "  if (length == 0):\n",
    "    return image_path\n",
    "  index = parts[length - 2]\n",
    "  if not index.isdigit():\n",
    "    return image_path\n",
    "  return int(index)\n",
    "\n",
    "def build_batch_jsons(main_dir, is_interior, start_idx):\n",
    "  subdirs = next(os.walk(main_dir))[1]\n",
    "  batch_jsonl_files = {}\n",
    "  c = len(subdirs)\n",
    "  for i, dir in enumerate(subdirs):\n",
    "    if i < start_idx:\n",
    "      continue\n",
    "    json_lines = []\n",
    "    additional_context = \"\"\n",
    "    if \"_i0_\" in dir:\n",
    "      additional_context = \"This view is facing diagonally upwards.\"\n",
    "    elif \"_i2_\" in dir:\n",
    "      additional_context = \"This view is facing diagonally downwards.\"\n",
    "    image_dir = f\"{batch_directory}/{dir}/outlines\"\n",
    "    image_files = get_ordered_files(image_dir)\n",
    "    for image in image_files:\n",
    "      line = build_batch_call_line(image, image, is_interior, additional_context)\n",
    "      json_lines.append(line)\n",
    "    path = f\"{batch_directory}/BatchRequest_{dir}.jsonl\"\n",
    "    with open(path, \"w\") as json_file:#\"w\" option will overwrite anything that is there if it exists.\n",
    "      for json_obj in json_lines:\n",
    "        json_file.write(json.dumps(json_obj) + '\\n')\n",
    "    batch_jsonl_files[dir] = path\n",
    "    print(f\"Saved request jsonl file {i + 1} of {c} at {path}\")\n",
    "\n",
    "  return batch_jsonl_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 178312,
     "status": "ok",
     "timestamp": 1726844564530,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "DuGDNg8I0rEx",
    "outputId": "10bf631e-1363-4635-f639-8b6fbaa2fbcb"
   },
   "outputs": [],
   "source": [
    "subdirs = next(os.walk(batch_directory))[1]\n",
    "print(subdirs)\n",
    "for dir in subdirs:\n",
    "  files = get_ordered_files(f\"{batch_directory}/{dir}\")\n",
    "  for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1726844567367,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "TtYk4uuWxWXq",
    "outputId": "f45addcf-5a1b-4c6c-cb23-28287d4fb671"
   },
   "outputs": [],
   "source": [
    "print(len(subdirs))\n",
    "for dir in subdirs:\n",
    "  print(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tO5SaK5yCxn"
   },
   "source": [
    "# Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6NfSg-GGQC-"
   },
   "outputs": [],
   "source": [
    "test_result = classify_image(test_image_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1723848270576,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "GlwR-lmC8bXT",
    "outputId": "f1b2c875-e7d4-4825-ab1f-6c0ca038e67d"
   },
   "outputs": [],
   "source": [
    "print(test_image_path)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YG3pc23m2GOW"
   },
   "source": [
    "# Batch JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 694336,
     "status": "ok",
     "timestamp": 1726238185182,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "awZxGQaQ2FBb",
    "outputId": "22b23866-dd0c-4e44-d3e5-fd337deb6b1b"
   },
   "outputs": [],
   "source": [
    "start_idx = 0 #this is to use if for some reason a previous run failed partially, like if the colab session got disconnected, it will start making batch request files at this index of the list\n",
    "batch_jsonl_files = build_batch_jsons(batch_directory, is_interior, start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1726238254745,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "EdriWieOFjmy",
    "outputId": "eb1372cf-fa18-45ab-83c7-ec9299af6399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    }
   ],
   "source": [
    "print(len(batch_jsonl_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDHIVwb-05X6"
   },
   "source": [
    "# Alternate workflow in cases of disconnected runtimes\n",
    "You can use this to restart classification if the previous runtime disconnected. Make sure you copy the batch_ids.txt and image classifications csv with unique names so they are not overwritten when you rerun classification. You should also use the batch_ids.txt file that was previously-generated to retrieve the old results from OpenAI, if you have not already done this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1726844902949,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "hqhlvcCb1YkR",
    "outputId": "34a75224-e296-4763-f150-4aef9e6fa853"
   },
   "outputs": [],
   "source": [
    "batch_jsonl_files = {} #clear the dictionary if anything is already in it, for this process, or create it new\n",
    "with open(f\"{batch_directory}/batch_ids_batch_1.txt\") as previous_batch_ids:\n",
    "  previously_processed_file_count = len(previous_batch_ids.readlines())\n",
    "  expected_additional_file_count = len(subdirs) - previously_processed_file_count\n",
    "  print(f\"Total batch count: {len(subdirs)}\")\n",
    "  print(f\"Previously processed batches: {previously_processed_file_count}\")\n",
    "  print(f\"Expected additional batches: {expected_additional_file_count}\")\n",
    "with open(f\"{batch_directory}/ImageClassifications_batch_1.csv\") as previous_csv: #just make this match whatever you renamed the previous classifications CSV as.\n",
    "  csv_string = previous_csv.read()\n",
    "  found_all = True\n",
    "  for dir in subdirs:\n",
    "    if dir in csv_string: #is this directory already classified? if so, skip it\n",
    "      continue\n",
    "    path = f\"{batch_directory}/BatchRequest_{dir}.jsonl\"\n",
    "    if not os.path.isfile(path):\n",
    "      found_all = False\n",
    "      print(f\"ERROR: file not found: {path}\")\n",
    "      continue\n",
    "    batch_jsonl_files[dir] = path\n",
    "  print(\"Found all necessary JSONL files\" if found_all else \"ERROR: not all necessary JSONL files exist\")\n",
    "  print(f\"Number of batches to process: {len(batch_jsonl_files)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2WKqLmPyHpa"
   },
   "source": [
    "# Actually Run the Batch Operation. Costs may add up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7358495,
     "status": "ok",
     "timestamp": 1726852330594,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "kIkiLtSKKcSl",
    "outputId": "940ee9d5-7781-4973-bbc7-2f39d4030e50"
   },
   "outputs": [],
   "source": [
    "batch_client_objects = {} #information about each asynchronous batch process, like ID, etc.\n",
    "file_count = len(batch_jsonl_files)\n",
    "log_path = f\"{batch_directory}/batch_ids.txt\"#logging the batch ids in case the process gets interrupted or instance is disconnected\n",
    "open(log_path, \"w\").close() #clear the file if there is anything in it from before\n",
    "for i, key in enumerate(batch_jsonl_files):\n",
    "  #https://platform.openai.com/docs/guides/batch/getting-started\n",
    "  jsonl_file = batch_jsonl_files[key]\n",
    "  batch_input_file = client.files.create(\n",
    "      file = open(jsonl_file, \"rb\"),\n",
    "      purpose = \"batch\"\n",
    "  )\n",
    "\n",
    "  batch_input_file_id = batch_input_file.id\n",
    "  print(f\"Preparing to send batch file {i + 1} of {file_count} for asynchronous processing\")\n",
    "  in_progress = False\n",
    "  while not in_progress:\n",
    "    batch_obj = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": \"batch label process\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    time_inc = 10\n",
    "    print(f\"Sent batch file {i + 1} of {file_count} for asynchronous processing, validating\")\n",
    "    status = \"\"\n",
    "    rtr_btc = None\n",
    "    while not in_progress:\n",
    "      print(\"waiting for validation...\")\n",
    "      time.sleep(time_inc)\n",
    "      rtr_btc = client.batches.retrieve(batch_obj.id)\n",
    "      status = rtr_btc.status\n",
    "      if status == \"validating\":\n",
    "        continue\n",
    "      if status == \"failed\":\n",
    "        break\n",
    "      in_progress = True\n",
    "\n",
    "    if not in_progress:\n",
    "      print(f\"Failed to send batch file {i + 1} of {file_count} for asynchronous processing, errors: {rtr_btc.errors}, will attempt again...\")\n",
    "    else:\n",
    "      batch_client_objects[key] = batch_obj\n",
    "      with open(log_path, \"a\") as logfile:\n",
    "        logfile.write(batch_obj.id + \"\\n\")\n",
    "      print(f\"Successfully sent batch file {i + 1} of {file_count} for asynchronous processing, status = {status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax36PdAELA4C"
   },
   "source": [
    "# Retrieve/check status of request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1HoHZoamMNnEm2XKs0rhrXfmiLjmn9TtA"
    },
    "executionInfo": {
     "elapsed": 117818,
     "status": "ok",
     "timestamp": 1726855604302,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "4d4009WS1aPq",
    "outputId": "2aef2217-4ed5-45c3-c88f-4815b7bfc61c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_ids_file = open(f\"{batch_directory}/batch_ids.txt\", 'r')\n",
    "batch_ids_lines = batch_ids_file.readlines()\n",
    "batch_ids_file.close()\n",
    "\n",
    "incomplete_batches = 0\n",
    "response_jsonl_paths = []\n",
    "for id_line in batch_ids_lines:\n",
    "  id = id_line.strip() #remove newline character\n",
    "  print(id)\n",
    "  retrieved_data = client.batches.retrieve(id)\n",
    "  if retrieved_data.status != \"completed\":\n",
    "    incomplete_batches += 1\n",
    "  try:\n",
    "    retrieved_text = client.files.content(retrieved_data.output_file_id).text\n",
    "  except:\n",
    "    print(\"error retreiving file, file id is likely invalid\")\n",
    "    continue\n",
    "  print(retrieved_text)\n",
    "  path = f\"{batch_directory}/BatchRequest_Retrieval_{id}.jsonl\"\n",
    "  with open(path, \"w\") as json_file:\n",
    "    json_file.write(retrieved_text)\n",
    "  response_jsonl_paths.append(path)\n",
    "\n",
    "print(\"All batches complete\" if incomplete_batches == 0 else f\"Not all batches complete (awaiting {incomplete_batches})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9lxHfJ5yRNV"
   },
   "source": [
    "# Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1726855613195,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "9nmPp3siGUoQ"
   },
   "outputs": [],
   "source": [
    "def cleanup_text(text):\n",
    "  parts = re.split('\\n|,', text)#clean up GPT's responses\n",
    "  fixed = \"\"\n",
    "  for p in parts:\n",
    "    fixed += p\n",
    "  return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2287,
     "status": "ok",
     "timestamp": 1726855619308,
     "user": {
      "displayName": "Stephen Hawking",
      "userId": "16164825628506018492"
     },
     "user_tz": 240
    },
    "id": "gAS3gBn3DUeZ",
    "outputId": "307e3a53-b826-4d7d-c725-9e8dc7f93a27"
   },
   "outputs": [],
   "source": [
    "csv = \"\"\n",
    "for path in response_jsonl_paths:\n",
    "  #read lines from jsonL file as json objects\n",
    "  retrieved_json_lines = []\n",
    "  with open(path) as f:\n",
    "    for line in f:\n",
    "      retrieved_json_lines.append(json.loads(line))\n",
    "\n",
    "  for retrieved_json_line in retrieved_json_lines:\n",
    "    #first, cull empty/invalid lines\n",
    "    if \"custom_id\" not in retrieved_json_line:\n",
    "      continue\n",
    "    img_path = retrieved_json_line[\"custom_id\"]\n",
    "    #print(img_path)\n",
    "    try:\n",
    "      response = retrieved_json_line['response']['body']['choices'][0]['message']['content']\n",
    "      print(response)\n",
    "      parts = response.split('+')\n",
    "      desc = cleanup_text(parts[0])\n",
    "      fam = cleanup_text(parts[1])\n",
    "      cat = cleanup_text(parts[2])\n",
    "      mat = cleanup_text(parts[3])\n",
    "      csv += img_path + \",\" + desc + \",\" + fam + \",\" + cat + \",\" + mat + \"\\n\"\n",
    "    except:\n",
    "      csv+= img_path + \",ERROR,ERROR,ERROR,\" + str(retrieved_json_line) + \"\\n\"\n",
    "\n",
    "print(csv)\n",
    "csv_file = open(f\"{batch_directory}/ImageClassifications.csv\", \"w\") #\"w\" option will overwrite anything that is there if it exists.\n",
    "csv_file.write(csv)\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNYmpWtFUr5muhAP0zGBpNO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
