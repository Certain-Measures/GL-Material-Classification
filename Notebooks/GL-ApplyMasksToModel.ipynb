{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTpt_TcAUs_2"
   },
   "source": [
    "# Setup\n",
    "\n",
    "additional information: https://github.com/niessner/Matterport/blob/master/data_organization.md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44580,
     "status": "ok",
     "timestamp": 1755008278791,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "vxYEyxysB76r",
    "outputId": "7436f599-f94a-4cb9-f97a-365a74f7e5c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"open3d\"])\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"trimesh\"])\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"imageio\"])\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pillow\"])\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tqdm\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeuTyhKbU6as"
   },
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1755008300062,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "q8Br6UlgU5R7"
   },
   "outputs": [],
   "source": [
    "camera_transforms_path = r\"G:/My Drive/GSD_AI/02_Models/Matterport/Matterport_Scans_Imgs/scans/17DRP5sb8fy/undistorted_camera_parameters/17DRP5sb8fy/undistorted_camera_parameters/17DRP5sb8fy.conf\"\n",
    "meshes_path = r\"G:/My Drive/GSD_AI/02_Models/Matterport/Matterport_Scans_Imgs/scans/17DRP5sb8fy/matterport_mesh/17DRP5sb8fy/_/matterport_mesh/bed1a77d92d64f5cbbaaae4feed64ec1/bed1a77d92d64f5cbbaaae4feed64ec1.obj\"\n",
    "depth_imgs_dir = r\"G:/My Drive//GSD_AI/02_Models/Matterport/Matterport_Scans_Imgs/scans/17DRP5sb8fy/undistorted_depth_images/17DRP5sb8fy/_/undistorted_depth_images\"\n",
    "color_imgs_dir = r\"G:/My Drive//GSD_AI/02_Models/Matterport/Matterport_Scans_Imgs/scans/17DRP5sb8fy/undistorted_color_images/17DRP5sb8fy/_/undistorted_color_images\"\n",
    "mask_imgs_dir = r\"G:/My Drive/GSD_AI/05_Segmentation/17DRP5sb8fy/SAM\"\n",
    "segmentation_data_csv_path = r\"G:/My Drive/GSD_AI/05_Segmentation/17DRP5sb8fy/SAM/ImageClassifications_collected.csv\"\n",
    "model_output_path = r\"C:/Repos/GL-Material-Classification/dbg.obj\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W397R5QYjET"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1755008300063,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "efea3kJ-YmOd"
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class CategoryType(Enum):\n",
    "    FAMILY = 2\n",
    "    CATEGORY = 3\n",
    "    MATERIAL = 4\n",
    "    \n",
    "img_width = 1280\n",
    "img_height = 1024\n",
    "scale_factor = 4000\n",
    "img_sample_stride = 10 #density of samples of depth maps, denser=slower but more accurate\n",
    "dist_threshold = 0.5 #max dist of raycast point to mesh\n",
    "category_colors = {'unknown': '#000000'} # categories that mesh faces can go into, starting with a special category of \"unknown\", which is used when a face has no classifications applied to it\n",
    "category_type = CategoryType.MATERIAL # the column from the CSV to extract for categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvjtxBcSYo0g"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6919,
     "status": "ok",
     "timestamp": 1755008306983,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "PoIOAuksYtL1"
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import open3d.core as o3c\n",
    "import trimesh\n",
    "from open3d.t.geometry import RaycastingScene\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from PIL import ImageColor\n",
    "import imageio.v3 as iio\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35750,
     "status": "ok",
     "timestamp": 1755008417763,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "OKqvstcPkT7J"
   },
   "outputs": [],
   "source": [
    "raw_scan = o3d.io.read_triangle_mesh(meshes_path)\n",
    "raw_scan.paint_uniform_color((0.25,0.25,0.25))\n",
    "#setup raycast scene\n",
    "ray_cast_scene = o3d.t.geometry.RaycastingScene()\n",
    "geom_id_to_mesh = {}\n",
    "\n",
    "full_mesh = o3d.t.geometry.TriangleMesh.from_legacy(raw_scan)\n",
    "geom_id = ray_cast_scene.add_triangles(full_mesh)\n",
    "print(geom_id)\n",
    "\n",
    "#geom_id_to_mesh[geom_id] = geom_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Materials Dictionary, Parse pregenerated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_hex_color():\n",
    "    \"\"\"Generates a random hexadecimal color code.\"\"\"\n",
    "    # Generate random integer values for red, green, and blue components (0-255)\n",
    "    r = random.randint(0, 255)\n",
    "    g = random.randint(0, 255)\n",
    "    b = random.randint(0, 255)\n",
    "\n",
    "    # Format the RGB values into a 6-digit hexadecimal string\n",
    "    # :02x ensures each component is formatted as a two-digit hexadecimal number,\n",
    "    # padding with a leading zero if necessary.\n",
    "    hex_color = f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "    return hex_color\n",
    "\n",
    "class MaskImage:\n",
    "   key = ''\n",
    "   mask_path = ''\n",
    "   categorization = ''\n",
    "\n",
    "   def __init__(self, key, path, cat):\n",
    "      self.key = key\n",
    "      self.mask_path = path\n",
    "      self.categorization = cat\n",
    "      return\n",
    "\n",
    "mask_imgs = []\n",
    "\n",
    "with open(segmentation_data_csv_path, 'r') as file:\n",
    "   lines = file.readlines()\n",
    "   ct = len(lines)\n",
    "   pbar = tqdm(total=ct)\n",
    "   for i, line in enumerate(lines):\n",
    "      line = line.strip()\n",
    "      sections = line.split(',')\n",
    "      orig_path = sections[0]\n",
    "      #desc = sections[1]\n",
    "      # fam = sections[2]\n",
    "      # cat = sections[3]\n",
    "      # mat = sections[4]\n",
    "      cat = sections[category_type.value]\n",
    "      cat = cat.strip()\n",
    "      if cat == '':\n",
    "         print(\"skipping image, no category provided\")\n",
    "         continue\n",
    "      if not cat in category_colors:\n",
    "         category_colors[cat] = generate_random_hex_color()\n",
    "      \n",
    "      sections = re.split(r'[/.]', orig_path)\n",
    "      mask_id = sections[len(sections) - 2]\n",
    "      key = sections[len(sections) - 4]\n",
    "      mask_path = f\"{mask_imgs_dir}/{key}/masks/{mask_id}.png\"\n",
    "      if not os.path.exists(mask_path):\n",
    "        print(f\"mask image not found: {mask_path}\")\n",
    "        continue\n",
    "      mask_imgs.append(MaskImage(key, mask_path, cat))\n",
    "      pbar.update(1)\n",
    "   pbar.close()\n",
    "   print(f\"processed {ct} lines of CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W97AEdBrbNo1"
   },
   "source": [
    "#### Check That Everything Imported\n",
    "Note that this will not work in Colab, only in jupyter notebooks running on your own setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 7562,
     "status": "ok",
     "timestamp": 1754948199916,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "zAAPyNIxZEnD",
    "outputId": "36dc2464-ad7f-4fba-c9e2-5ddc68313c55"
   },
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([raw_scan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQV_ASTKbxwQ"
   },
   "source": [
    "#### Load Camera Transforms and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1755013246276,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "S4HYq0nQb1-b",
    "outputId": "92a9e25b-942e-45e6-dc5e-6ce54d583189"
   },
   "outputs": [],
   "source": [
    "class camera_pose_data:\n",
    "\n",
    "  camera_transform = np.empty(0)\n",
    "  depth_img = \"\"\n",
    "  color_img = \"\"\n",
    "  focal_len_x_pixels, focal_len_y_pixels, camera_center_x_pixels, camera_center_y_pixels = 0, 0, 0, 0\n",
    "  camera_position = np.array([[0.0, 0.0, 0.0]])\n",
    "  mask_imgs = []\n",
    "  def __init__(self, depth_img, color_img, camera_transform, focal_len_x_pixels, focal_len_y_pixels, camera_center_x_pixels, camera_center_y_pixels):\n",
    "    self.depth_img = depth_img\n",
    "    self.color_img = color_img\n",
    "    self.camera_transform = camera_transform\n",
    "    self.focal_len_x_pixels = focal_len_x_pixels\n",
    "    self.focal_len_y_pixels = focal_len_y_pixels\n",
    "    self.camera_center_x_pixels = camera_center_x_pixels\n",
    "    self.camera_center_y_pixels = camera_center_y_pixels\n",
    "    return\n",
    "\n",
    "camera_poses = {}\n",
    "try:\n",
    "  with open(camera_transforms_path, 'r') as file:\n",
    "    focal_len_x_pixels, focal_len_y_pixels, camera_center_x_pixels, camera_center_y_pixels = 0, 0, 0, 0\n",
    "    for i, line in enumerate(file):\n",
    "      clean_line = line.strip()\n",
    "      sections = clean_line.split(' ')\n",
    "      cleaned_sections = []\n",
    "      for s in sections:\n",
    "        if (s != ''):\n",
    "          cleaned_sections.append(s)\n",
    "      sections = cleaned_sections\n",
    "\n",
    "      ct = len(sections)\n",
    "      if (ct < 10):\n",
    "        continue\n",
    "      if (sections[0] == \"intrinsics_matrix\" and ct == 10):\n",
    "        focal_len_x_pixels = float(sections[1])\n",
    "        focal_len_y_pixels = float(sections[5])\n",
    "        camera_center_x_pixels = float(sections[3])\n",
    "        camera_center_y_pixels = float(sections[6])\n",
    "      if (sections[0] != \"scan\"):\n",
    "        continue\n",
    "      if (ct != 19):\n",
    "        print(f\"ERROR: Unexpected number of sections in line {i}\")\n",
    "      depth_img_path = depth_imgs_dir + \"/\" + sections[1]\n",
    "      rgb_img_path = color_imgs_dir + \"/\" + sections[2]\n",
    "\n",
    "      if (not os.path.exists(depth_img_path) or not os.path.exists(rgb_img_path)):\n",
    "        print(f\"ERROR: File not found: {depth_img_path} {rgb_img_path}\")\n",
    "        continue\n",
    "      t = np.eye(4)#empty 4x4 transform matrix\n",
    "      for r in range(0, 4):\n",
    "        for c in range (0, 4):\n",
    "          ray_idx = 3 + (r * 4) + c\n",
    "          t[r, c] = float(sections[ray_idx])\n",
    "\n",
    "      #rotate 180degrees around x axis--it was found that doing this extra transform was necessary rather than relying on the imported transform by itself\n",
    "      #upper left 3x3 part of the 4x4 transform matrix is the rotation matrix\n",
    "      #this gives us rotate_x = [[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]\n",
    "      #matrix for rotating about x-axis: Rx(t)= [[1, 0, 0], [0, cos(t), -sin(t)], [0, sin(t), cos(t)]]\n",
    "      rotate_x = np.eye(4)\n",
    "      rotate_x[1,1] = -1\n",
    "      rotate_x[2,2] = -1\n",
    "      t = t @ rotate_x\n",
    "\n",
    "      pose = camera_pose_data(depth_img_path, rgb_img_path, t, focal_len_x_pixels, focal_len_y_pixels, camera_center_x_pixels, camera_center_y_pixels)\n",
    "\n",
    "      #get image key\n",
    "      sections = re.split(r'[/.]', rgb_img_path)\n",
    "      key = sections[len(sections) - 2]\n",
    "      #print(f\"image name: {key}\")\n",
    "      if not key in camera_poses:\n",
    "        camera_poses[key] = pose\n",
    "      else:\n",
    "        print(f\"key already found in dictionary: {key}\")\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "  print(f\"File not found: {camera_transforms_path}\")\n",
    "\n",
    "print(f\"successfully imported {len(camera_poses)} poses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755013249060,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "dEC6LQb7j4fs",
    "outputId": "c51e1894-94e7-41fe-b641-6f10a52c1e78"
   },
   "outputs": [],
   "source": [
    "print(camera_poses[next(iter(camera_poses))].camera_transform) #check that transform values came in properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfyjaa9UpymO"
   },
   "source": [
    "# Process Depth Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1755013250614,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "sNvQo4ft7pHx",
    "outputId": "9c1b4eec-a6f8-4d66-df72-166c0b604168"
   },
   "outputs": [],
   "source": [
    "#check that file loads and has a valid type\n",
    "#images are uint16 pngs where each integer increment = 0.25mm (/4000 to get meters)\n",
    "\n",
    "img = o3d.io.read_image(camera_poses[next(iter(camera_poses))].depth_img)\n",
    "print(\"dtype:\", np.asarray(img).dtype)\n",
    "print(\"min/max:\", np.min(np.asarray(img)), np.max(np.asarray(img)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5672,
     "status": "ok",
     "timestamp": 1755013259965,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "kLcAOv9ipFye",
    "outputId": "8977cbd2-0dbe-4cc3-d096-fd0311cf7b1f"
   },
   "outputs": [],
   "source": [
    "def depth_to_point_cloud(depth_img, stride, intrinsic, scale):\n",
    "    depth_np = np.asarray(depth_img).astype(np.float32) / float(scale)\n",
    "    h, w = depth_np.shape\n",
    "    fx, fy = intrinsic.get_focal_length()\n",
    "    cx, cy = intrinsic.get_principal_point()\n",
    "\n",
    "    # Create meshgrid of pixel coordinates\n",
    "    u, v = np.meshgrid(np.arange(0, w, stride), np.arange(0, h, stride))\n",
    "    z = depth_np[::stride, ::stride]\n",
    "    x = (u - cx) * z / fx\n",
    "    y = (v - cy) * z / fy\n",
    "\n",
    "    points = np.stack((x, y, z), axis=-1).reshape(-1, 3)\n",
    "    pixel_coords = np.stack((u, v), axis=-1).reshape(-1, 2)\n",
    "    validity_map = []\n",
    "    for p in points:\n",
    "      if (p[0] == 0 and p[1] == 0  and p[2] == 0 ):\n",
    "        validity_map.append(False)\n",
    "      else:\n",
    "        validity_map.append(True)\n",
    "    points = points[validity_map]\n",
    "\n",
    "    return points, validity_map, pixel_coords\n",
    "\n",
    "depth_clouds = {}\n",
    "validity_maps = {}\n",
    "pixel_maps = {}\n",
    "camera_positions = []\n",
    "ct = len(camera_poses)\n",
    "i = 0\n",
    "pbar = tqdm(total = ct)\n",
    "for key in camera_poses:\n",
    "  pose = camera_poses[key]\n",
    "  img = o3d.io.read_image(pose.depth_img)\n",
    "  #print(pose.depth_img)\n",
    "  #img = iio.imread(pose.depth_img)\n",
    "  intrinsic = o3d.camera.PinholeCameraIntrinsic(width = img_width, height = img_height, fx = pose.focal_len_x_pixels, fy = pose.focal_len_y_pixels, cx = pose.camera_center_x_pixels, cy = pose.camera_center_y_pixels)\n",
    "  #o3d was crashing when applying project_valid_depth_only = False and stride > 1. We need information for each sample, not just valid ones.\n",
    "  cloud_pts, validity_map, pixel_coords = depth_to_point_cloud(img, img_sample_stride, intrinsic, scale_factor)\n",
    "  validity_maps[key] = validity_map\n",
    "  pixel_maps[key] = pixel_coords\n",
    "  cloud = o3d.geometry.PointCloud()\n",
    "  cloud.points = o3d.utility.Vector3dVector(cloud_pts)\n",
    "\n",
    "  # don't do this:\n",
    "  # cloud = o3d.geometry.PointCloud.create_from_depth_image(img,\n",
    "  #                                                               intrinsic,\n",
    "  #                                                               depth_scale = scale_factor,\n",
    "  #                                                               depth_trunc = 50,\n",
    "  #                                                               stride = img_sample_stride,\n",
    "  #                                                               project_valid_depth_only = False)\n",
    "\n",
    "  # Get Camera Position transformed\n",
    "  camera_position = cam_pos_world = pose.camera_transform[:3, 3]\n",
    "  pose.camera_position = camera_position\n",
    "  camera_positions.append(camera_position)\n",
    "\n",
    "  #transform the depth cloud\n",
    "  cloud.transform(pose.camera_transform)\n",
    "  depth_clouds[key] = cloud\n",
    "  # print(f\"cloud size: {len(cloud.points)}\")\n",
    "  # print(f\"{str(i + 1)} of {str(ct)}\")\n",
    "  pbar.update(1)\n",
    "  i += 1\n",
    "  # if (i > 50):\n",
    "  #   break\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify depth clouds match model.\n",
    "You can look at a specific image and visually-inspect if the point cloud is aligning properly with the model. Some minor deviation and random noise is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clds = []\n",
    "# for cloud in depth_clouds:\n",
    "#     clds.append(depth_clouds[cloud])\n",
    "# o3d.visualization.draw_geometries([raw_scan, clds[20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MBGz4ZNq0Ca"
   },
   "source": [
    "# Denoise Point Clouds\n",
    "\n",
    "Check each point cloud point and make sure it is close to mesh. If not, remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9423,
     "status": "ok",
     "timestamp": 1754949573115,
     "user": {
      "displayName": "Gavin Ruedisueli",
      "userId": "18338223940445004250"
     },
     "user_tz": 240
    },
    "id": "WQ4C6_z-q-Vv",
    "outputId": "8380bbbd-bb53-48c5-ef1b-b64aa62170d0"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    \"Calculates the Euclidean distance between two 3D points.\"\n",
    "    point1 = np.asarray(point1)\n",
    "    point2 = np.asarray(point2)\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "\n",
    "face_id_maps = {}\n",
    "#geometry_id_maps = {}\n",
    "\n",
    "ct = len(depth_clouds)\n",
    "mod_validity_maps = validity_maps.copy()\n",
    "cloudpts = []\n",
    "i = -1\n",
    "pbar = tqdm(total=ct)\n",
    "for key in depth_clouds:\n",
    "  i += 1\n",
    "  \n",
    "  cloud = depth_clouds[key]\n",
    "  v_map = mod_validity_maps[key]\n",
    "  pose = camera_poses[key]\n",
    "\n",
    "  ray_sources = []\n",
    "  ray_targets = []\n",
    "  map_size = len(v_map)\n",
    "  local_valid_map = v_map.copy()\n",
    "  local_triangle_ids = np.full(map_size, -1)\n",
    "\n",
    "  #get ray sources/targets\n",
    "  #this needs to be limited to valid parts of the depth image, to get a ray that is valid\n",
    "  position = pose.camera_position\n",
    "  valid_ct = 0\n",
    "  #print(f\"pt ct: {len(cloud.points)}\")\n",
    "  cloudIdx = 0\n",
    "  for ray_idx, v in enumerate(local_valid_map):\n",
    "    if not local_valid_map[ray_idx]:\n",
    "      continue\n",
    "    point = cloud.points[cloudIdx]\n",
    "    cloudIdx += 1\n",
    "    ray_sources.append(position)\n",
    "    ray_targets.append(point)\n",
    "    cloudpts.append(point)\n",
    "    valid_ct += 1\n",
    "  #print(f\"starting valid ct: {valid_ct}\")\n",
    "\n",
    "  #normalize the rays\n",
    "  #print(f\"ray ct: {len(ray_sources)}\")\n",
    "  rays_sources = np.array(ray_sources)\n",
    "  rays_targets = np.array(ray_targets)\n",
    "  directions = ray_targets - rays_sources\n",
    "  norms = np.linalg.norm(directions, axis=1, keepdims= True)\n",
    "  directions_normalized = directions / norms\n",
    "  rays = o3c.Tensor(np.hstack((rays_sources, directions_normalized)), dtype=o3c.Dtype.Float32)\n",
    "\n",
    "  #compute\n",
    "  results = ray_cast_scene.cast_rays(rays)\n",
    "  hit_points = ray_sources + directions_normalized * results[\"t_hit\"].numpy()[..., None]\n",
    "\n",
    "  #bring values from shortened \"valid\" ray list back to the full array\n",
    "  map_idx = 0\n",
    "  for ray_idx, ids in enumerate(results['primitive_ids']):\n",
    "    id = ids.item()\n",
    "    if  id == RaycastingScene.INVALID_ID:\n",
    "      local_valid_map[map_idx] = False\n",
    "      continue\n",
    "    hp = hit_points[ray_idx]\n",
    "    dist = euclidean_distance(ray_targets[ray_idx], hp)\n",
    "    if (dist > dist_threshold):\n",
    "      local_valid_map[map_idx] = False\n",
    "      continue\n",
    "\n",
    "\n",
    "    local_valid_map[map_idx] = True\n",
    "    local_triangle_ids[map_idx] = id\n",
    "    map_idx += 1\n",
    "\n",
    "  face_id_maps[key] = local_triangle_ids\n",
    "\n",
    "  mod_validity_maps[key] = local_valid_map\n",
    "  pbar.update(1)\n",
    "  # print(f\"ending valid ct: {valid_ct}\")\n",
    "  # print(len(results['primitive_ids']))\n",
    "  # print(f\"{str(i + 1)} of {str(ct)}\")\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Segmentation Results to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_id_categories = np.zeros((len(full_mesh.triangle.indices), len(category_colors)), dtype=np.int32)\n",
    "print(f\"size of face id to categories array: {face_id_categories.shape}\")\n",
    "mask_ct = 0\n",
    "cat_list = list(category_colors)\n",
    "\n",
    "def process_mask(m_img):\n",
    "    key = m_img.key\n",
    "    path = m_img.mask_path\n",
    "    cat = m_img.categorization\n",
    "\n",
    "    try:\n",
    "        #pose = camera_poses[key]\n",
    "        v_map = validity_maps[key]\n",
    "        pixel_coords = pixel_maps[key]\n",
    "        face_ids = face_id_maps[key]\n",
    "    except KeyError:\n",
    "        print(f\"{key} not found in dictionary. Are you processing a subset of frames?\")\n",
    "        return None\n",
    "\n",
    "    cat_id = cat_list.index(cat)\n",
    "    img = iio.imread(path)\n",
    "\n",
    "    valid_indices = np.where(v_map)[0]\n",
    "    coords = pixel_coords[valid_indices]\n",
    "    face_ids_valid = face_ids[valid_indices]\n",
    "    pix_vals = img[coords[:, 1], coords[:, 0]]\n",
    "    mask_hits = (pix_vals != 0)\n",
    "    selected_face_ids = face_ids_valid[mask_hits]\n",
    "\n",
    "    # Accumulate counts locally\n",
    "    local_counts = defaultdict(int)\n",
    "    for fid in selected_face_ids:\n",
    "        local_counts[fid] += 1\n",
    "\n",
    "    return (cat_id, local_counts)\n",
    "\n",
    "# Multithreaded execution\n",
    "mask_ct = 0\n",
    "pbar = tqdm(total=len(mask_imgs))\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(process_mask, m_img) for m_img in mask_imgs]\n",
    "    for future in futures:\n",
    "        result = future.result()\n",
    "        if result is None:\n",
    "            continue\n",
    "        cat_id, local_counts = result\n",
    "        for fid, count in local_counts.items():\n",
    "            face_id_categories[fid, cat_id] += count\n",
    "        mask_ct += 1\n",
    "        #print(f\"Processed {mask_ct} of {len(mask_imgs)}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "print(f\"successfully processed {mask_ct} masks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide vote winners\n",
    "For each mesh face, the material with the most votes wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = []\n",
    "colors = []\n",
    "mesh_faces_by_category = {}\n",
    "for cat in cat_list:\n",
    "    mesh_faces_by_category[cat] = []\n",
    "for i, face_tallies in enumerate(face_id_categories):\n",
    "    #print(str(face_tallies))\n",
    "    if np.max(face_tallies) == 0:\n",
    "        max_idx = 0\n",
    "    else:\n",
    "        max_idx = np.argmax(face_tallies)\n",
    "    #print(str(max_idx))\n",
    "    w = cat_list[max_idx]\n",
    "    winners.append(w)\n",
    "    mesh_faces_by_category[w].append(i)\n",
    "    colors.append(np.array(ImageColor.getcolor(category_colors[w], \"RGB\"))/255.0)\n",
    "print(\"winners determined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Mesh by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles = full_mesh.triangle[\"indices\"].numpy()\n",
    "vertices = full_mesh.vertex[\"positions\"].numpy()\n",
    "meshes_by_category = {}\n",
    "for key in mesh_faces_by_category:\n",
    "    face_ids = mesh_faces_by_category[key]\n",
    "    if len(face_ids) == 0:\n",
    "        continue\n",
    "    # Get triangle data (array shape (N,3)), vertex indices for each triangle\n",
    "    selected_triangles = triangles[face_ids]\n",
    "    # Get unique vertices\n",
    "    unique_vertex_indices = np.unique(selected_triangles)\n",
    "    # make a dictionary that maps the old vertex indices to new ones for the new mesh that will be created\n",
    "    old_to_new = {old_idx: new_idx for new_idx, old_idx in enumerate(unique_vertex_indices)} # eg old_to_new = {7: 0, 19: 1, 42: 2}\n",
    "    remapped_triangles = np.vectorize(old_to_new.get)(selected_triangles) # eg np.vectorize(old_to_new.get)([42, 7, 19]) â†’ [2, 0, 1], creates a function that then you call with the param of selected_triangles\n",
    "    # extract vertex positions\n",
    "    new_vertices = vertices[unique_vertex_indices]\n",
    "    # create new tensor mesh\n",
    "    new_mesh = o3d.geometry.TriangleMesh()\n",
    "    new_mesh.vertices = o3d.utility.Vector3dVector(new_vertices)\n",
    "    new_mesh.triangles = o3d.utility.Vector3iVector(remapped_triangles)\n",
    "\n",
    "    #color by material\n",
    "    c = np.array(ImageColor.getcolor(category_colors[key], \"RGB\"))/255.0\n",
    "    new_mesh.paint_uniform_color(c)\n",
    "\n",
    "    # store mesh in dictionary\n",
    "    meshes_by_category[key] = new_mesh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize\n",
    "preview_mesh = meshes_by_category['wood']\n",
    "o3d.visualization.draw_geometries(\n",
    "    [preview_mesh],\n",
    "    zoom=0.7,\n",
    "    front=[0, 0, -1],\n",
    "    lookat=preview_mesh.get_center(),\n",
    "    up=[0, -1, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def o3d_to_trimesh(o3d_mesh):\n",
    "    vertices = np.asarray(o3d_mesh.vertices)\n",
    "    faces = np.asarray(o3d_mesh.triangles)\n",
    "    return trimesh.Trimesh(vertices=vertices, faces=faces)\n",
    "\n",
    "trimesh_scene = trimesh.Scene()\n",
    "for key in meshes_by_category:\n",
    "    t_mesh = o3d_to_trimesh(meshes_by_category[key])\n",
    "    trimesh_scene.add_geometry(t_mesh, geom_name=key)\n",
    "\n",
    "trimesh_scene.export(model_output_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNfJkFQPpwpnOU1h4cQQvTw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
